{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NeuralCMS Jupyter Notebook\n",
    "In this notebook, we will load the pre-trained NeuralCMS model and use it to compute a single interior model of Jupiter. Additionally, we will use it to perform a grid search of interior models consistent with Juno gravity data. NeuralCMS receives seven inputs parameters setting the interior model and outputs the gravity moments and mass of the modeled Jupiter.\n",
    "\n",
    "Further information can be found in Ziv et. al. 2024.\n",
    "\n",
    "Contact: <maayan.ziv@weizmann.ac.il>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the trained models\n",
    "Load the trained model that predicts the gravity moments ($J_2\\times10^6$, $-J_4\\times10^6$, $J_6\\times10^6$, and $-J_8\\times10^6$) and the mass$\\times10^{-27}$ kg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from models_architecture import SharedNN # import the sharing-based model architecture\n",
    "\n",
    "net_Js = SharedNN(input_size=7)\n",
    "net_Js.load_state_dict(torch.load('trained_model_Js.pt',map_location=torch.device('cpu')))\n",
    "net_Js.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the trained model that predicts only the mass (more accurately then the model above)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models_architecture import FCNN # import the fully-connected model architecture\n",
    "\n",
    "net_mass = FCNN(input_size=7,output_size=1)\n",
    "net_mass.load_state_dict(torch.load('trained_model_mass_only.pt',map_location=torch.device('cpu')))\n",
    "net_mass.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helping functions to normalize and un-normalize the inputs:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function receives an array of size N*7, and normalizes the inputs to be between 0-1 using Min-Max, with the bounds of the training dataset\n",
    "def norm_inputs(input_):\n",
    "    input_[:,0] = (input_[:,0] - 0.1) / (0.6 - 0.1)\n",
    "    input_[:,1] = (input_[:,1] - 0.5) / (5 - 0.5)\n",
    "    input_[:,2] = (input_[:,2] - 0) / (0.12 - 0)\n",
    "    input_[:,3] = (input_[:,3] - 159) / (190 - 159)\n",
    "    input_[:,4] = (input_[:,4] - 0.27) / (0.286 - 0.27)\n",
    "    input_[:,5] = (input_[:,5] - 0.005) / (0.06 - 0.005)\n",
    "    input_[:,6] = (input_[:,6] - 0.01) / (0.6 - 0.01)\n",
    "    return input_\n",
    "\n",
    "# This function receives an array of size N*7, and un-normalizes the inputs to their true values by inverting the Min-Max normalization, using the bounds of the training dataset\n",
    "def unnorm_inputs(input_):\n",
    "    input_[:,0] = input_[:,0]*(0.6 - 0.1) + 0.1\n",
    "    input_[:,1] = input_[:,1]*(5 - 0.05) + 0.5\n",
    "    input_[:,2] = input_[:,2]*(0.12 - 0) + 0\n",
    "    input_[:,3] = input_[:,3]*(190 - 159) + 159\n",
    "    input_[:,4] = input_[:,4]*(0.286 - 0.270) + 0.27\n",
    "    input_[:,5] = input_[:,5]*(0.06 - 0.005) + 0.005\n",
    "    input_[:,6] = input_[:,6]*(0.6 - 0.01) + 0.01\n",
    "    return input_"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Computing a single interior model\n",
    "![Kernel & front-end diagram](plots/NeuralCMS_inputs_table.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As an example, we provided parameter values for a specific model.\n",
    "Users should replace the parameter values to their interests within the bounds shown above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the interior model parameters: make sure that Z1<=Z_dilute!!\n",
    "Y_proto = 0.27705264\n",
    "T_1bar = 180.47369\n",
    "Z1 = 0.014210527\n",
    "P12 = 0.8\n",
    "m_dilute = 0.38210526\n",
    "Z_dilute = 0.15263158\n",
    "r_core = 0.06947095\n",
    "\n",
    "# Prepare the input vector and normalize it\n",
    "input_vec = np.array([[m_dilute, P12, r_core, T_1bar, Y_proto, Z1, Z_dilute]])\n",
    "input_vec = norm_inputs(input_vec)\n",
    "input_vec = torch.tensor(input_vec, dtype=torch.float32)\n",
    "\n",
    "# Make a prediction using NeuralCMS\n",
    "with torch.no_grad():\n",
    "    pred = net_Js(input_vec) # Predict the Js and the less accurate mass\n",
    "    pred[:,4] = torch.reshape(net_mass(input_vec),(-1,)) # Accurately predict the mass using a separate network\n",
    "\n",
    "# Prepare the outputs\n",
    "J2 = +pred[0][0].numpy() # J2*10^6\n",
    "J4 = -pred[0][1].numpy() # J4*10^6\n",
    "J6 = +pred[0][2].numpy() # J6*10^6\n",
    "J8 = -pred[0][3].numpy() # J8*10^6\n",
    "mass = +pred[0][4].numpy() # mass*10^-27 kg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print NeuralCMS results and compare them with the Juno gravity data (Durante et al., 2020, DOI:[10.1029/2019GL086572](https://ui.adsabs.harvard.edu/link_gateway/2020GeoRL..4786572D/doi:10.1029/2019GL086572))."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Js_NeuralCMS = [J2, J4, J6, J8, mass] # NeuralCMS predictions\n",
    "Js_Juno = [14696.5735, -586.6085, 34.2007, -2.422, 1.8982532] # Juno measurements (Durante et al., 2020)\n",
    "\n",
    "# Define headers\n",
    "header1 = \"Juno\"\n",
    "header2 = \"NeuralCMS\"\n",
    "\n",
    "# Print headers\n",
    "print(f\"{header1:<10} {header2:<10}\")\n",
    "\n",
    "# Print values\n",
    "for value1, value2 in zip(Js_Juno[:5], Js_NeuralCMS[:5]):\n",
    "    print(f\"{value1:<10} {value2:<10}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performing a grid search for interior models consistent with Juno gravity data\n",
    "We perform a grid search exploring all possible combinations of an equally spaced grid for each of the seven parameters with $m$ grid points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helping functions to effectively compute batches of $10^6$ interior model simultaneously"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "# This function generates a single interior model from the 7D gridded data\n",
    "def generate_grid_data(grids, batch_size):\n",
    "    for grid_point in itertools.product(*grids):\n",
    "        yield grid_point\n",
    "\n",
    "# This function generates a batch of interior models from the 7D gridded data\n",
    "def batch_generator(generator, batch_size):\n",
    "    batch = []\n",
    "    for item in generator:\n",
    "        batch.append(item)\n",
    "        if len(batch) == batch_size:\n",
    "            yield batch\n",
    "            batch = []\n",
    "    if batch:\n",
    "        yield batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the grid for each parameter by the number of grid points and its bounds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m = 10 # number of grid points for each parameter\n",
    "\n",
    "# For each parameter we define a list with the bounds and number of grid points:\n",
    "# [minimum value, maximum value, number of grid points]\n",
    "Y_proto_bounds = [0.272, 0.284, m]\n",
    "T_1bar_bounds = [159, 187, m]\n",
    "# As an example, to restrict a parameter to a specific value, set its number of grid points to 1 and the bounds to the specific value: Z1_bounds = [0.02, 0.02, 1]\n",
    "Z1_bounds = [0.005, 0.06, m]\n",
    "P12_bounds = [0.8, 5, m]\n",
    "m_dilute_bounds = [0.11, 0.6, m]\n",
    "Z_dilute_bounds = [0.06, 0.45, m] # make sure that Z1<=Z_dilute!!\n",
    "r_core_bounds = [0, 0.12, m]\n",
    "\n",
    "# Generate the 7D grid data\n",
    "mdil = np.linspace(m_dilute_bounds[0], m_dilute_bounds[1], m_dilute_bounds[2])\n",
    "p12 = np.linspace(P12_bounds[0], P12_bounds[1], P12_bounds[2])\n",
    "rc = np.linspace(r_core_bounds[0], r_core_bounds[1], r_core_bounds[2])\n",
    "t1bar = np.linspace(T_1bar_bounds[0], T_1bar_bounds[1], T_1bar_bounds[2])\n",
    "yproto = np.linspace(Y_proto_bounds[0], Y_proto_bounds[1], Y_proto_bounds[2])\n",
    "z1 = np.linspace(Z1_bounds[0], Z1_bounds[1], Z1_bounds[2])\n",
    "zdil = np.linspace(Z_dilute_bounds[0], Z_dilute_bounds[1], Z_dilute_bounds[2])\n",
    "\n",
    "# Grids for each dimension\n",
    "dimension_grids = [mdil,p12,rc,t1bar,yproto,z1,zdil]\n",
    "\n",
    "# 1 million grid points per batch\n",
    "batch_size = 1000000\n",
    "\n",
    "# The data generator\n",
    "grid_data_generator = generate_grid_data(dimension_grids, batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the grid search procedure, and accept models that are within a chosen prediction error from the Juno measurements. We provide the errors on the validation dataset used during training. You can choose either the maximal absolute prediction errors, the $3\\sigma$ errors, or the $1\\sigma$ errors.\n",
    "Also, a range to allow deviations from the Juno measurements can be added to the prediction errors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Js_Juno = [14696.5735, 586.6085, 34.2007, 2.422, 1.8982532] # Juno measurements (Durante et al., 2020)\n",
    "\n",
    "# As an example, we will find models that are consistent only with J2*10^6, J4*10^6, and the mass*10^-27 kg\n",
    "range_from_Juno = [2,1,0,0,0.0005] # Only the non-zero entries are important in this case\n",
    "\n",
    "# Choose you preferred prediction errors (pred_error_choice):\n",
    "# set it to 1 for 1-sigma, 3 for 3-sigma, or the default, which is the maximum absolute errors\n",
    "pred_error_choice = 0\n",
    "if pred_error_choice == 1:\n",
    "    pred_errs = [0.78904, 0.049011, 0.0044912, 0.00032655, 7.3513e-05]\n",
    "elif pred_error_choice == 3:\n",
    "    pred_errs = 3 * [0.78904, 0.049011, 0.0044912, 0.00032655, 7.3513e-05]\n",
    "else:\n",
    "    pred_errs = [7.855,0.53317,0.096413,0.0044255,0.0019912]\n",
    "\n",
    "# Iterate over grid data in batches\n",
    "for batch_idx, batch in enumerate(tqdm(batch_generator(grid_data_generator, batch_size), desc=\"Processing batches\"),start=1):\n",
    "\n",
    "    # Normalize the inputs\n",
    "    inputs_grid_ = norm_inputs(np.array(batch))\n",
    "    inputs_grid_ = torch.tensor(inputs_grid_, dtype=torch.float32)\n",
    "\n",
    "    # Make the prediction for the whole batch\n",
    "    with torch.no_grad():\n",
    "        predictions = net_Js(inputs_grid_)\n",
    "        predictions[:,4] = torch.reshape(net_mass(inputs_grid_),(-1,))\n",
    "\n",
    "    # Save the predictions and the inputs that are consistent with Juno in temporarily variables\n",
    "    tmp_pred = predictions[np.where((abs(predictions[:,0]-Js_Juno[0]) <= pred_errs[0]+range_from_Juno[0]) & \\\n",
    "                                    (abs(predictions[:,1]-Js_Juno[1]) <= pred_errs[1]+range_from_Juno[1]) & \\\n",
    "                                    (abs(predictions[:,4]-Js_Juno[4]) <= pred_errs[4]+range_from_Juno[4]))]\n",
    "    tmp_inputs = inputs_grid_[np.where((abs(predictions[:,0]-Js_Juno[0]) <= pred_errs[0]+range_from_Juno[0]) & \\\n",
    "                                    (abs(predictions[:,1]-Js_Juno[1]) <= pred_errs[1]+range_from_Juno[1]) & \\\n",
    "                                    (abs(predictions[:,4]-Js_Juno[4]) <= pred_errs[4]+range_from_Juno[4]))]\n",
    "\n",
    "    # If it is the first batch, make the temporarily variables the accumulated lists\n",
    "    if batch_idx == 1:\n",
    "        pred = tmp_pred\n",
    "        inputs_out = unnorm_inputs(tmp_inputs) # Un-normalize the inputs\n",
    "    # Concatenate the acceptable models from the current batch with the previous models accepted previously\n",
    "    else:\n",
    "        pred = torch.cat((pred, tmp_pred), dim=0)\n",
    "        inputs_out = torch.cat((inputs_out, unnorm_inputs(tmp_inputs)), dim=0) # save the un-normalize the inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a final step, transform the results to numpy arrays.\n",
    "Now you have two arrays:\n",
    "- accepted_inputs, sized N*7, where the dimensions are in the following order:\n",
    "  $m_{\\rm dilute}$, $P_{12}$, $r_{\\rm core}$, $T_{\\rm 1 bar}$, $Y_{\\rm proto}$, $Z_1$, and $Z_{\\rm dilute}$\n",
    "- accepted_predictions, sized N*5, where the dimensions are in the following order:\n",
    "  $J_{2}\\times10^{6}$, $-J_{4}\\times10^{6}$, $J_{6}\\times10^{6}$, $-J_{8}\\times10^{6}$, and mass$\\times10^{-27}$ kg."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accepted_inputs = inputs_out.numpy()\n",
    "accepted_predictions = pred.numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
